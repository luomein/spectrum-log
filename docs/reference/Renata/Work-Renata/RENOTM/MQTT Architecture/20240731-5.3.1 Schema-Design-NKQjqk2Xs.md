# 5.3.1 Schema-Design

## Einleitung

Schema-Design ist entscheidend für die effiziente Speicherung, Verarbeitung und Analyse unserer Produktionsdaten. Es berücksichtigt sowohl die Anforderungen an Echtzeitverarbeitung als auch an langfristige Analysen.

## Grundprinzipien

Bei der Entwicklung unseres Schema-Designs haben ich folgende Prinzipien beachtet:

1. Flexibilität: Anpassungsfähig an verschiedene Datentypen und zukünftige Erweiterungen
2. Leistung: Optimiert für schnelle Abfragen und Analysen
3. Skalierbarkeit: Geeignet für große Datenmengen und hohe Einfügeraten
4. Konsistenz: Einheitliche Struktur über verschiedene Datenquellen hinweg
5. Kompression: Effiziente Speichernutzung durch geeignete Datentypen und Komprimierung

## Haupt-Datenmodelle

### 1. Telemetriedaten-Schema

Dieses Schema wird für die Mehrzahl unserer Sensordaten verwendet.

```json
{
  "device_id": "string",
  "timestamp": "datetime",
  "measurement_type": "string",
  "value": "double",
  "unit": "string",
  "quality": "integer",
  "metadata": {
    "location": "string",
    "production_line": "string",
    "sensor_type": "string"
  }
}
```

### 2. Maschinenstatus-Schema

Für die Erfassung von Maschinenzuständen und Ereignissen.

```json
{
  "machine_id": "string",
  "timestamp": "datetime",
  "status": "string",
  "event_type": "string",
  "duration": "integer",
  "operator_id": "string",
  "details": {
    "error_code": "string",
    "severity": "string"
  }
}
```

### 3. Produktionscharge-Schema

Zur Verfolgung von Produktionschargen und Qualitätsdaten.

```json
{
  "batch_id": "string",
  "product_id": "string",
  "start_time": "datetime",
  "end_time": "datetime",
  "quantity": "integer",
  "quality_metrics": {
    "defect_rate": "double",
    "yield": "double"
  },
  "process_parameters": [
    {
      "parameter_name": "string",
      "value": "double",
      "unit": "string"
    }
  ]
}
```

## Spezifische Schemas für Renata SA

### 1. Präzisionsmessung-Schema

Für hochpräzise Messungen in der Batterieproduktion.

```json
{
  "measurement_id": "string",
  "timestamp": "datetime",
  "component_id": "string",
  "dimension": "string",
  "actual_value": "double",
  "tolerance_min": "double",
  "tolerance_max": "double",
  "unit": "string",
  "measurement_device": "string",
  "operator_id": "string"
}
```

### 2. Batterieleistung-Schema

Zur Überwachung und Analyse der Batterieproduktion.

```json
{
  "battery_id": "string",
  "test_timestamp": "datetime",
  "voltage": "double",
  "capacity": "double",
  "internal_resistance": "double",
  "temperature": "double",
  "charge_cycles": "integer",
  "chemistry": "string",
  "production_line": "string"
}
```

## Datentypen und Formatierung

- Zeitstempel: ISO 8601 Format (z.B. "2024-01-15T14:30:00Z")
- Numerische Werte: Doubles für Messungen, Integers für Zähler
- Strings: UTF-8 kodiert, maximal 256 Zeichen
- Enums: Für festgelegte Wertelisten (z.B. Maschinenstatus, Fehlertypen)

## Partitionierung und Indexierung

### Azure Cosmos DB

- Partitionsschlüssel: `device_id` oder `machine_id` für gleichmäßige Datenverteilung
- Indexierung:
  - Standardindexierung für alle Felder
  - Zusammengesetzte Indizes für häufige Abfragemuster (z.B. `device_id` und `timestamp`)

### Azure Data Lake Storage Gen2

- Partitionierung:
  - Jahr/Monat/Tag-Hierarchie für effiziente Zeitbereichsabfragen
  - Zusätzliche Partitionierung nach `production_line` oder `product_id`

## Datenvalidierung und -bereinigung

1. Wertebereichsprüfungen für numerische Daten
2. Formatvalidierung für Zeitstempel und IDs
3. Enum-Validierung für kategorische Daten
4. Nullwert-Behandlung: Explizite Nullwerte statt fehlender Felder

## Versionierung und Evolution

- Schemaversion als Metadatenfeld in jedem Datensatz
- Backward-kompatible Schemaänderungen bevorzugt
- Bei größeren Änderungen: Parallele Verarbeitung alter und neuer Schemaversionen

## Datenkompression und -optimierung

- Verwendung von Apache Parquet für analytische Workloads
- Snappy-Kompression für ein ausgewogenes Verhältnis von Kompressionsrate und Leistung
- Partitionierte Materialized Views in Cosmos DB für häufige Abfragemuster

## Sicherheit und Compliance

- Verschlüsselung sensibler Daten auf Feldebene
- Implementierung von dynamischer Datenmaskierung für personenbezogene Daten
- DSGVO-konforme Datenklassifizierung und Aufbewahrungsrichtlinien

## Integration mit Analysewerkzeugen

- Kompatibilität mit Azure Synapse Analytics für komplexe Abfragen
- Optimierte Schemas für Power BI-Berichte und -Dashboards
- Unterstützung für maschinelles Lernen mit Azure Machine Learning

## Beispielabfragen

1. Durchschnittliche Temperatur pro Produktionslinie in den letzten 24 Stunden:

```sql
SELECT 
    metadata.production_line,
    AVG(value) as avg_temperature
FROM 
    telemetry_data
WHERE 
    measurement_type = 'temperature'
    AND timestamp > DATEADD(hour, -24, GETUTCDATE())
GROUP BY 
    metadata.production_line
```

2. Identifikation von Qualitätsabweichungen in der Präzisionsfertigung:

```sql
SELECT 
    component_id,
    actual_value,
    tolerance_min,
    tolerance_max
FROM 
    precision_measurements
WHERE 
    actual_value < tolerance_min OR actual_value > tolerance_max
    AND timestamp > DATEADD(day, -7, GETUTCDATE())
```

## Nächste Schritte und Optimierungen

1. Implementierung eines automatisierten Schema-Validierungsprozesses in der CI/CD-Pipeline
2. Entwicklung eines Tools zur Schema-Evolution und -Migration
3. Regelmäßige Performance-Analysen und Optimierung der Indexierungsstrategien
4. Erweiterung des Schemas um IoT-Edge-spezifische Metadaten für verbesserte Nachverfolgbarkeit

## Fazit

Das hier vorgestellte Schema-Design bildet eine solide Grundlage und es ermöglicht uns, die vielfältigen Daten aus unserer Produktion effizient zu erfassen, zu speichern und zu analysieren.