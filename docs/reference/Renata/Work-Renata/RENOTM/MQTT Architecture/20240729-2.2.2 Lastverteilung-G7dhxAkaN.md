# 2.2.2 Lastverteilung


## Einführung

Eine effektive Lastverteilung ist entscheidend für die Leistung und Zuverlässigkeit unseres EMQX-Clusters im IIoT-Projekt.

## Lastverteilungsstrategie

Unsere Lastverteilungsstrategie basiert auf einem mehrschichtigen Ansatz, der sowohl externe als auch interne Lastverteilungsmechanismen nutzt.

### 1. Externe Lastverteilung

#### Azure Load Balancer

Wir setzen den Azure Load Balancer als primären Eingangspunkt für den Client-Verkehr ein.

Konfiguration:
- Typ: Azure Standard Load Balancer
- Verteilungsmodus: Hash-basiert (Quell-IP und Port)
- Session Persistenz: Client IP
- Protokoll: TCP für MQTT, HTTP für WebSocket

Einstellungen:
- Idle Timeout: 4 Minuten (angepasst an MQTT Keep-Alive)
- Floating IP: Aktiviert für direkte Server-Rückantwort
- TCP Reset on Idle: Aktiviert

#### Azure Traffic Manager

Für globale Lastverteilung und Geo-Redundanz implementieren wir Azure Traffic Manager.

Konfiguration:
- Routing-Methode: Performance
- Endpunkte: Mehrere regionale Azure Load Balancer
- Health Checks: Alle 30 Sekunden

### 2. Interne Lastverteilung

#### EMQX Built-in Load Balancing

EMQX bietet integrierte Lastverteilungsmechanismen, die wir wie folgt konfigurieren:

- Verbindungsverteilung: Round-Robin
- Nachrichtenverteilung: Konsistentes Hashing basierend auf Topic
- Shared Subscriptions: Aktiviert für gleichmäßige Verteilung von Nachrichten an Subscriber-Gruppen

#### Datenbankverbindungen

Für Datenbankzugriffe implementieren wir Connection Pooling:

- Pool-Größe: Initial 10, maximal 100 Verbindungen pro Node
- Idle Timeout: 60 Sekunden
- Verbindungswiederverwendung: Aktiviert

### 3. Skalierungsstrategie

Wir implementieren eine dynamische Skalierungsstrategie basierend auf Leistungsmetriken:

- Horizontale Skalierung: Automatisches Hinzufügen neuer EMQX-Nodes bei 70% CPU-Auslastung
- Vertikale Skalierung: Manuelle Anpassung der VM-Größe basierend auf Speicher- und CPU-Bedarf

## Leistungsoptimierung

### 1. Verbindungsmanagement

- Connection Rate Limiting: Max. 5000 neue Verbindungen pro Sekunde pro Node
- Max. Connections per Node: 1 Million (anpassbar basierend auf VM-Größe)

### 2. Nachrichtenverarbeitung

- QoS-basierte Priorisierung: QoS 2 > QoS 1 > QoS 0
- Message Rate Limiting: Max. 100.000 Nachrichten pro Sekunde pro Node
- Payload Size Limit: 256 KB

### 3. Topic-Optimierung

- Implementierung einer flachen Topic-Struktur zur Reduzierung der Routing-Komplexität
- Verwendung von Topic-Aliassen zur Reduzierung der Overhead-Größe

## Monitoring und Anpassung

Wir implementieren ein umfassendes Monitoring-System zur kontinuierlichen Überwachung und Optimierung der Lastverteilung:

- Echtzeit-Metriken: Verbindungen, Nachrichten/Sekunde, Latenz, CPU- und Speicherauslastung
- Dashboards: Grafana für visuelle Darstellung der Leistungsmetriken
- Alerting: Automatische Benachrichtigungen bei Überschreitung definierter Schwellenwerte

Anpassungsmaßnahmen:
- Wöchentliche Leistungsüberprüfungen
- Monatliche Feinabstimmung der Lastverteilungsparameter
- Vierteljährliche Kapazitätsplanung und -anpassung

## Failover und Hochverfügbarkeit

Unsere Lastverteilungsstrategie ist eng mit unserer Hochverfügbarkeitsstrategie verknüpft:

- Automatisches Failover: Bei Ausfall eines Nodes leitet der Load Balancer den Verkehr automatisch auf gesunde Nodes um
- Cross-Zone Load Balancing: Verteilung des Verkehrs über mehrere Verfügbarkeitszonen in Azure
- Disaster Recovery: Automatische Umleitung zu einem sekundären Cluster in einer anderen Region bei großflächigen Ausfällen

## Implementierungsplan

1. Einrichtung und Konfiguration des Azure Load Balancers
2. Implementierung des Azure Traffic Managers für globale Lastverteilung
3. Konfiguration der internen EMQX-Lastverteilungsmechanismen
4. Einrichtung des Monitoring- und Alerting-Systems
5. Durchführung von Lasttests zur Validierung der Konfiguration
6. Feinabstimmung basierend auf Testergebnissen
7. Dokumentation und Schulung des Betriebsteams

## Fazit
Die regelmäßige Überprüfung und Anpassung dieser Strategie wird sicherstellen, dass wir auch zukünftigen Anforderungen und Wachstum gerecht werden.