# 7.2 Auto-Skalierung

## Einführung

Auto-Skalierung ist ein wesentlicher Bestandteil der IIoT-Infrastruktur. Sie ermöglicht es uns, dynamisch auf Lastschwankungen zu reagieren und stellt sicher, dass unsere EMQX MQTT-Broker-Cluster stets optimal dimensioniert sind.

## Ziele der Auto-Skalierung

1. Automatische Anpassung der Ressourcen an den aktuellen Bedarf
2. Kostenoptimierung durch Vermeidung von Über- oder Unterprovisionierung
3. Aufrechterhaltung der Leistung und Verfügbarkeit bei Lastspitzen
4. Minimierung manueller Eingriffe bei der Ressourcenverwaltung

## Auto-Skalierungsstrategien

### 1. Horizontale Pod-Autoskalierung (HPA)

Wir nutzen die Kubernetes Horizontal Pod Autoscaler (HPA) für die automatische Skalierung unserer EMQX-Pods:

```yaml
apiVersion: autoscaling/v2beta1
kind: HorizontalPodAutoscaler
metadata:
  name: emqx-autoscaler
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: emqx
  minReplicas: 3
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      targetAverageUtilization: 70
  - type: Resource
    resource:
      name: memory
      targetAverageUtilization: 80
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 100
        periodSeconds: 15
    scaleUp:
      stabilizationWindowSeconds: 0
      policies:
      - type: Percent
        value: 100
        periodSeconds: 15
      - type: Pods
        value: 4
        periodSeconds: 15
      selectPolicy: Max
```

### 2. Vertikale Pod-Autoskalierung (VPA)

Ergänzend zur HPA implementieren wir die Vertical Pod Autoscaler für die Optimierung der Ressourcenzuweisung:

```yaml
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: emqx-vpa
spec:
  targetRef:
    apiVersion: "apps/v1"
    kind: Deployment
    name: emqx
  updatePolicy:
    updateMode: "Auto"
  resourcePolicy:
    containerPolicies:
    - containerName: '*'
      minAllowed:
        cpu: 100m
        memory: 50Mi
      maxAllowed:
        cpu: 4
        memory: 8Gi
      controlledResources: ["cpu", "memory"]
```

### 3. Cluster-Autoskalierung

Für die Skalierung des gesamten AKS-Clusters nutzen wir den Azure Kubernetes Service Cluster Autoscaler:

```bash
az aks update \
  --resource-group myResourceGroup \
  --name myAKSCluster \
  --enable-cluster-autoscaler \
  --min-count 3 \
  --max-count 10
```

## Metriken für die Auto-Skalierung

1. CPU-Auslastung
2. Arbeitsspeicher-Auslastung
3. Anzahl aktiver MQTT-Verbindungen
4. Nachrichtendurchsatz (Nachrichten pro Sekunde)
5. Netzwerkauslastung

## Implementierung benutzerdefinierter Metriken

Für EMQX-spezifische Metriken implementieren wir einen Custom Metrics Server:

1. Deployment des Prometheus Adapter:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: prometheus-adapter
spec:
  replicas: 1
  selector:
    matchLabels:
      name: prometheus-adapter
  template:
    metadata:
      labels:
        name: prometheus-adapter
    spec:
      containers:
      - name: prometheus-adapter
        image: directxman12/k8s-prometheus-adapter:v0.8.3
        args:
        - --prometheus-url=http://prometheus-server.monitoring.svc:9090
        - --metrics-relist-interval=1m
        - --v=6
        - --config=/etc/adapter/config.yaml
        ports:
        - containerPort: 6443
```

2. Konfiguration benutzerdefinierter Metriken:

```yaml
apiVersion: custom.metrics.k8s.io/v1beta1
kind: CustomMetric
metadata:
  name: emqx_connections
spec:
  query: sum(emqx_connections_count)
```

3. Anpassung des HPA für benutzerdefinierte Metriken:

```yaml
apiVersion: autoscaling/v2beta1
kind: HorizontalPodAutoscaler
metadata:
  name: emqx-autoscaler
spec:
  metrics:
  - type: Pods
    pods:
      metricName: emqx_connections
      targetAverageValue: 10000
```

## Skalierungsrichtlinien

1. Aggressive Hochskalierung:
   - Sofortige Reaktion auf Lastspitzen
   - Skalierung in größeren Schritten (z.B. +50% oder +4 Pods)

2. Konservative Herunterskalierung:
   - Verzögerung von 5 Minuten vor dem Herunterskalieren
   - Skalierung in kleineren Schritten (z.B. -25% oder -1 Pod)

3. Cooldown-Perioden:
   - 3 Minuten Cooldown nach Hochskalierung
   - 5 Minuten Cooldown nach Herunterskalierung

## Überwachung und Feinabstimmung

1. Implementierung detaillierter Logging für Skalierungsereignisse
2. Einrichtung von Grafana-Dashboards zur Visualisierung der Skalierungsaktivitäten
3. Wöchentliche Überprüfung der Skalierungsmetriken und -schwellenwerte
4. Monatliche Analyse der Kosteneffizienz der Auto-Skalierung

## Alarmierung

Konfiguration von Warnungen für:
- Fehlgeschlagene Skalierungsoperationen
- Erreichen der maximalen Skalierungsgrenzen
- Ungewöhnliche Skalierungsmuster

## Notfallplan

1. Manuelle Übersteuerungsmöglichkeit für kritische Situationen
2. Vordefinierte Skalierungsprofile für bekannte Lastspitzen (z.B. geplante Wartungsarbeiten)
3. Failover-Prozedur bei Ausfall der Auto-Skalierung

## Implementierungsplan

1. Einrichtung der Horizontal Pod Autoscaler für EMQX-Deployments
2. Konfiguration des Vertical Pod Autoscaler
3. Aktivierung und Konfiguration des AKS Cluster Autoscaler
4. Implementierung und Test des Custom Metrics Server
5. Einrichtung des Monitoring- und Alerting-Systems
6. Durchführung von Lasttests zur Validierung der Auto-Skalierung
7. Feinabstimmung der Skalierungsparameter basierend auf Testergebnissen

## Fazit

Die implementierte Auto-Skalierungsstrategie ermöglicht es uns, flexibel und effizient auf Lastschwankungen zu reagieren. Durch die Kombination von horizontaler und vertikaler Skalierung sowie benutzerdefinierter Metriken erreichen wir eine optimale Ressourcennutzung bei gleichzeitiger Gewährleistung der Systemleistung und -verfügbarkeit.