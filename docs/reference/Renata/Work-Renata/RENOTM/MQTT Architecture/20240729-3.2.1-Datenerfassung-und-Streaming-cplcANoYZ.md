# 3.2.1-Datenerfassung-und-Streaming

## Einführung

Azure Event Hubs spielt eine zentrale Rolle in unserer IIoT-Architektur als skalierbarer und zuverlässiger Dienst für die Erfassung und Verarbeitung von Echtzeit-Datenströmen. Dieses Dokument beschreibt, wie wir Event Hubs für die nahtlose Integration mit EMQX nutzen, um eine effiziente Ende-zu-Ende-Datenverarbeitung zu ermöglichen.

## Architekturübersicht

In unserer Architektur fungiert EMQX als primärer MQTT-Broker, der Gerätedaten von verschiedenen Produktionslinien und Sensoren sammelt. Diese Daten werden dann über eine EMQX-Regelengine verarbeitet und an Azure Event Hubs weitergeleitet.

```
Sensoren/Geräte -> EMQX -> Regelengine -> Azure Event Hubs -> Stream Analytics -> Data Lake
```

## Event Hub Erstellung und Konfiguration

1. Erstellen eines neuen Event Hubs-Namespaces im Azure-Portal
2. Konfigurieren der Zugriffsrichtlinien und Verbindungszeichenfolgen
3. Erstellen eines Event Hubs für jede wichtige Datenquelle (z.B. Produktionslinie, Sensortyp)
4. Konfigurieren der Nachrichtenaufbewahrung und Durchsatzeinheiten basierend auf dem erwarteten Datenvolumen

## Integration mit EMQX

Wir nutzen die leistungsstarke Regelengine von EMQX, um eingehende MQTT-Nachrichten zu transformieren und an die entsprechenden Event Hubs weiterzuleiten.

1. Erstellen von Regeln in der EMQX-Web-Konsole für jede Datenquelle
2. Konfigurieren der Regelaktion zum Weiterleiten von Nachrichten an Event Hubs unter Verwendung der Event Hub-Verbindungszeichenfolge
3. Festlegen der Nachrichtenformatierung (z.B. JSON) und Zuordnung der MQTT-Themenfelder zu Event Hub-Nachrichteneigenschaften
4. Aktivieren der Regelengine zur Initiierung des Datenflusses

Beispielregel zum Weiterleiten von Temperaturdaten an einen Event Hub:

```sql
SELECT 
  payload.temperature AS temperature,
  payload.sensor_id AS sensor_id,
  payload.timestamp AS timestamp
FROM
  "renata/gebaeude2/+/+/sensor/+/temperatur"
```

## Überwachung und Fehlerbehebung

Zur Gewährleistung eines reibungslosen Datenflusses und zur proaktiven Problembehandlung implementieren wir eine umfassende Überwachung.

1. Verwenden von Azure Monitor zum Nachverfolgen von Event Hub-Metriken wie eingehende Nachrichten, Datenträgerbytes und Anforderungen
2. Konfigurieren von Warnungen für wichtige Schwellenwerte wie Drosselungsfehler oder hohe Latenzzeiten
3. Korrelieren von Protokollen und Metriken zwischen EMQX und Event Hubs zur effektiven Fehlerbehebung
4. Durchführung regelmäßiger Durchsatztests und Kapazitätsplanungen zur Sicherstellung der Skalierbarkeit

## Downstream-Integration

Die in Event Hubs erfassten Daten bilden die Grundlage für nachfolgende Echtzeitanalysen und Batch-Verarbeitungen.

1. Verwenden von Azure Stream Analytics für die Echtzeit-Datenaggregation, -filterung und -anreicherung
2. Landen von Stream Analytics-Ergebnissen in Azure Data Lake für die langfristige Speicherung und Batch-Analysen
3. Aktivieren von Event Hub Capture zur direkten Archivierung von Rohereignisdaten in Azure Blob Storage
4. Integration mit Azure Functions für ereignisgesteuerte Verarbeitung und Geschäftslogik

## Fazit

Durch die Integration von EMQX und Azure Event Hubs schaffen wir eine robuste und skalierbare Pipeline für die Erfassung und Verarbeitung von IIoT-Daten in Echtzeit.