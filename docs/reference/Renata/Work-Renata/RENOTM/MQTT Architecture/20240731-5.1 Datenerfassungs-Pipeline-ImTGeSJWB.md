# 5.1 Datenerfassungs-Pipeline

## Einleitung

Die Datenerfassungs-Pipeline ist ein zentraler Bestandteil unseres Projekts. Es ermöglicht die effiziente und zuverlässige Sammlung, Verarbeitung und Weiterleitung von Daten aus unseren Produktionsanlagen in die Cloud-Infrastruktur. Diese Pipeline ist entscheidend für die Echtzeitüberwachung, Analyse und Optimierung unserer Fertigungsprozesse.

## Architektur der Datenerfassungs-Pipeline

Unsere Datenerfassungs-Pipeline besteht aus folgenden Hauptkomponenten:

1. Datenquellen (Sensoren und SPS)
2. Edge-Gateways
3. EMQX MQTT Broker
4. Azure IoT Hub
5. Azure Event Hubs
6. Azure Stream Analytics

### Datenfluss

1. Sensoren und SPS → Edge-Gateways
2. Edge-Gateways → EMQX MQTT Broker
3. EMQX MQTT Broker → Azure IoT Hub
4. Azure IoT Hub → Azure Event Hubs
5. Azure Event Hubs → Azure Stream Analytics

## Detaillierte Komponenten

### 1. Datenquellen

- Sensoren: Temperatur-, Druck-, Vibrations- und Präzisionssensoren von Endress+Hauser
- SPS: Siemens S7-1500 für Produktionsliniensteuerung
- Datenerfassungssysteme: HBM QuantumX für hochpräzise Messungen

Datenformate:
- JSON für strukturierte Daten
- Binary für Rohdaten von Sensoren

### 2. Edge-Gateways

- Hardware: Moxa ThingsPro Gateway
- Software: 
  - NanoMQ für lokale MQTT-Verarbeitung
  - Azure IoT Edge Runtime für Edge-Computing-Funktionen

Funktionen:
- Datenvorverarbeitung und -filterung
- Lokale Datenaggregation
- Protokollumwandlung (z.B. Modbus zu MQTT)
- Pufferung bei Netzwerkausfällen

### 3. EMQX MQTT Broker

- Version: EMQX Enterprise 4.4.x
- Deployment: Azure Kubernetes Service (AKS)

Konfiguration:
- QoS-Levels: 
  - QoS 2 für kritische Produktionsdaten
  - QoS 1 für reguläre Telemetriedaten
  - QoS 0 für nicht-kritische Statusupdates
- Topic-Struktur: Gemäß unseren Naming-Konventionen (siehe Dokument 2.3.1)

### 4. Azure IoT Hub

- SKU: S1 – Standard Tier
- Partitionen: 4 (skalierbar)

Funktionen:
- Geräteverwaltung und -authentifizierung
- Nachrichtenrouting zu Azure-Diensten
- Device Twins für Gerätekonfiguration und -status

### 5. Azure Event Hubs

- SKU: Standard
- Durchsatzeinheiten: 10 (autoskalierend)
- Nachrichtenaufbewahrung: 7 Tage

### 6. Azure Stream Analytics

- Streaming Units: 6 (skalierbar)

Funktionen:
- Echtzeitdatenverarbeitung
- Komplexe Ereignisverarbeitung (CEP)
- Datenaggregation und -filterung

## Datenverarbeitungslogik

1. Edge-Verarbeitung:
   - Datenvalidierung und -bereinigung
   - Lokale Aggregation (z.B. Durchschnittsbildung über 5 Sekunden)
   - Anomalieerkennung für sofortige lokale Reaktionen

2. EMQX-Verarbeitung:
   - Nachrichtenvalidierung
   - Topic-basiertes Routing
   - Einfache Transformationen mittels EMQX Rule Engine

3. Stream Analytics-Verarbeitung:
   - Komplexe Berechnungen (z.B. OEE-Berechnung)
   - Zeitfensterbasierte Aggregationen
   - Korrelation von Daten aus verschiedenen Quellen

## Datenmodell und Schemas

Wir verwenden ein flexibles JSON-Schema für die meisten Datenpunkte:

```json
{
  "device_id": "string",
  "timestamp": "ISO8601 datetime",
  "measurement_type": "string",
  "value": "number",
  "unit": "string",
  "quality": "number (0-100)"
}
```

Für spezielle Datentypen (z.B. Spektralanalysen) werden angepasste Schemas verwendet.

## Fehlerbehandlung und Resilienz

1. Edge-Level:
   - Lokale Datenpufferung bei Netzwerkausfällen
   - Automatische Wiederverbindungsversuche

2. EMQX-Level:
   - Message Queueing für QoS 1 und 2 Nachrichten
   - Cluster-basierte Hochverfügbarkeit

3. Azure-Level:
   - Event Hubs Capture für Langzeitspeicherung aller Rohdaten
   - Dead-Letter Queues für nicht verarbeitbare Nachrichten

## Monitoring und Logging

- EMQX Dashboard für MQTT-spezifische Metriken
- Azure Monitor für End-to-End-Überwachung
- Anpassbare Alarmierung basierend auf definierten Schwellenwerten
- Zentralisiertes Logging mit Azure Log Analytics

## Skalierbarkeit und Performance

- Aktuelle Kapazität: 100.000 Nachrichten/Sekunde
- Skalierungsstrategie: 
  - Horizontale Skalierung von EMQX-Nodes
  - Vertikale Skalierung von Azure-Ressourcen

## Sicherheitsaspekte

- TLS 1.2 Verschlüsselung für alle Kommunikation
- X.509-Zertifikate für Geräteauthentifizierung
- Netzwerksegmentierung zwischen OT und IT
- Regelmäßige Sicherheitsaudits und Penetrationstests

## Nächste Schritte und Optimierungen

1. Implementierung von MQTT 5.0 Features für verbesserte Effizienz
2. Erweiterung der Edge-Analytics-Fähigkeiten
3. Integration von ML-Modellen für prädiktive Wartung
4. Optimierung der Datenpartitionierung in Event Hubs für bessere Leistung

## Fazit

Die hier beschriebene Datenerfassungs-Pipeline bildet das Rückgrat unserer IIoT-Infrastruktur. Sie ermöglicht uns die effiziente Erfassung, Verarbeitung und Analyse von Produktionsdaten in Echtzeit. Durch die Kombination von Edge-Computing, MQTT-Messaging und Azure-Cloud-Diensten haben wir eine skalierbare, resiliente und zukunftssichere Lösung geschaffen, die den hohen Anforderungen unserer Präzisionsfertigung gerecht wird.