# 3.4.1 Langzeitspeicherung

## Einführung

Azure Data Lake Storage Gen2 (ADLS Gen2) bietet uns die ideale Plattform, um große Mengen strukturierter und unstrukturierter Daten kostengünstig und sicher zu speichern und zu analysieren.

## Architektur

Wir implementieren eine mehrstufige Datenarchitektur:

1. Hot Tier: Aktuelle Daten (0-30 Tage)
2. Cool Tier: Häufig benötigte historische Daten (31-90 Tage)
3. Archive Tier: Langzeitarchivierung (> 90 Tage)

## Konfiguration

### Speicherkonto-Einstellungen

- Name: renataiiotdatalake
- Leistung: Premium
- Redundanz: Georedundanter Speicher (GRS)
- Hierarchischer Namespace: Aktiviert
- Verschlüsselung: Azure-verwalteter Schlüssel

### Zugriffsebenen

- Standard-Zugriffsebene: Hot
- Lebenszyklusverwaltung: Aktiviert
   - Cool Tier nach 30 Tagen
   - Archive Tier nach 90 Tagen

### Sicherheit

- Netzwerk: Privater Endpunkt innerhalb des Azure-VNet
- Firewall: Aktiviert, Zugriff nur aus definierten IP-Bereichen
- Verschlüsselung im Ruhezustand: Aktiviert mit kundenseitig verwalteten Schlüsseln (CMK)

## Datenorganisation

Wir strukturieren unsere Daten wie folgt:

```
renataiiotdatalake/
├── raw/
│   ├── produktionslinie1/
│   │   ├── YYYY/
│   │   │   ├── MM/
│   │   │   │   ├── DD/
│   │   │   │   │   ├── HH/
│   │   │   │   │   │   ├── sensor_data.parquet
│   │   │   │   │   │   └── machine_logs.json
│   ├── produktionslinie2/
│   └── ...
├── processed/
│   ├── daily_aggregations/
│   ├── quality_metrics/
│   └── oee_calculations/
└── analytics/
    ├── ml_models/
    └── dashboards/
```

## Datenaufnahme

1. MQTT-Nachrichten werden von EMQX an Azure Event Hubs gesendet
2. Azure Stream Analytics verarbeitet die Daten in Echtzeit
3. Rohdaten und verarbeitete Daten werden in ADLS Gen2 geschrieben

## Datenzugriff und Analyse

- Azure Synapse Analytics für SQL-basierte Abfragen und Analysen
- Azure Databricks für komplexe Datenverarbeitung und Machine Learning
- Power BI für Visualisierung und Berichterstattung

## Daten-Lifecycle-Management

- Implementierung von Azure Policy für automatische Datenklassifizierung
- Regelmäßige Überprüfung und Optimierung der Lifecycle-Regeln
- Jährliche Archivierungsüberprüfung für Compliance-Zwecke

## Kostenoptimierung

- Verwendung von Blob Index für effiziente Metadatensuche
- Implementierung von Azure Reserved Capacity für vorhersehbare Workloads
- Regelmäßige Kostenanalyse und Optimierung mit Azure Cost Management

## Monitoring und Wartung

- Azure Monitor für Leistungsüberwachung und Alarmierung
- Automated Tiering für optimale Kosteneffizienz
- Regelmäßige Integritätsprüfungen und Datenkonsistenz-Checks

## Disaster Recovery

- Geo-redundante Speicherung (GRS) für Datensicherheit
- Implementierung von Azure Site Recovery für kritische Workloads
- Jährliche Disaster-Recovery-Tests und -Dokumentation

## Fazit

Die Implementierung von Azure Data Lake Storage Gen2 für die Langzeitspeicherung unserer IIoT-Daten bietet eine skalierbare, sichere und kosteneffiziente Lösung.