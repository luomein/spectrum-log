# 3.3.1-Echtzeitverarbeitung

## Einführung

Azure Stream Analytics ist ein essentieller Bestandteil unserer IIoT-Architektur, der es uns ermöglicht, Echtzeiteinblicke aus unseren Produktionsdaten zu gewinnen. Dieses Dokument beschreibt, wie wir Stream Analytics nutzen, um kontinuierliche Datenströme von Azure Event Hubs zu analysieren und so zeitnahe und umsetzbare Erkenntnisse für unser Produktion zu gewinnen.

## Architekturübersicht

In unserem IIoT-Datenfluss fungiert Stream Analytics als Bindeglied zwischen der Datenerfassung und der Persistenz- und Visualisierungsschicht.

```
Azure Event Hubs -> Stream Analytics -> Azure Data Lake / Power BI
```

Stream Analytics-Jobs lesen Daten aus Event Hubs, führen Echtzeitabfragen und -analysen durch und leiten die Ergebnisse an nachgelagerte Senken wie Azure Data Lake für die Batch-Verarbeitung oder Power BI für Echtzeitdashboards weiter.

## Erstellung und Konfiguration von Stream Analytics-Jobs

1. Erstellen eines neuen Stream Analytics-Jobs im Azure-Portal
2. Konfigurieren von Event Hubs als Eingabequelle für den Job
3. Definieren der Abfragelogik mit der Stream Analytics Query Language (SAQL)
4. Konfigurieren von Ausgabesenken wie Azure Data Lake oder Power BI
5. Anpassen der Streamingeinheiten und Partitionierung basierend auf dem erwarteten Datenvolumen und der Komplexität der Abfrage

## Entwicklung von Echtzeitabfragen

Wir nutzen SAQL, um leistungsstarke Echtzeitabfragen für verschiedene IIoT-Anwendungsfälle zu entwickeln, darunter:

1. Datenfilterung und -aggregation:
   - Filtern von Sensordaten nach bestimmten Schwellenwerten oder Bedingungen
   - Berechnen von Durchschnittswerten, Summen und anderen Aggregationen über gleitende Zeitfenster

2. Anomalieerkennung:
   - Identifizieren von ungewöhnlichen Mustern oder Abweichungen in Echtzeit
   - Generieren von Warnungen bei Überschreitung vordefinierter Grenzwerte

3. Datenkorrelation:
   - Verknüpfen von Datenströmen aus verschiedenen Quellen anhand gemeinsamer Felder
   - Anreichern von Sensordaten mit Metadaten oder Referenzdaten

4. Berechnung von KPIs:
   - Implementierung von Geschäftslogik zur Berechnung von Schlüsselkennzahlen wie OEE oder Energieverbrauch
   - Aggregieren von KPIs auf verschiedenen Granularitätsebenen (z.B. pro Produktionslinie, Schicht oder Werk)

Beispielabfrage zur Berechnung der durchschnittlichen Temperatur pro Sensor über ein 5-Minuten-Fenster:

```sql
SELECT
  AVG(temperature) AS avg_temperature,
  sensor_id
FROM
  input
GROUP BY
  sensor_id,
  TumblingWindow(minute, 5)
```

## Integration mit Visualisierungstools

Um Echtzeitdaten für Stakeholder zugänglich und handlungsfähig zu machen, integrieren wir Stream Analytics nahtlos mit Visualisierungstools wie Power BI.

1. Konfigurieren von Power BI als Ausgabesenke für Stream Analytics-Jobs
2. Entwerfen interaktiver Dashboards in Power BI, um Echtzeitmetriken und KPIs darzustellen
3. Einrichten von Warnungen und Benachrichtigungen basierend auf vordefinierten Schwellenwerten
4. Optimieren der Dashboardleistung durch Anpassung von Visualisierungsparametern und Cachingeinstellungen

## Überwachung und Skalierung

Um eine optimale Leistung und Kosteneffizienz zu gewährleisten, implementieren wir eine robuste Überwachung und Skalierungsstrategien für unsere Stream Analytics-Jobs.

1. Verwenden von Azure Monitor zum Nachverfolgen von Stream Analytics-Metriken wie Eingabeereignisse, Ausgabeereignisse und Ausführungsverzögerung
2. Konfigurieren von Warnungen für schlüsselfertige Leistungsmetriken und Fehlerbedingungen  
3. Dynamisches Anpassen der Streamingeinheiten basierend auf dem Eingabedurchsatz und der Abfragekomplexität
4. Regelmäßiges Überprüfen und Optimieren von Abfrageleistung und Ressourcenverbrauch

## Spezifische Anwendungsfälle bei Renata SA

1. Echtzeitüberwachung kritischer Qualitätsparameter:
   - Kontinuierliche Analyse von Sensordaten zur Identifizierung von Qualitätsabweichungen
   - Sofortige Benachrichtigung des Produktionspersonals bei Überschreitung von Toleranzgrenzen

2. Optimierung des Energieverbrauchs:  
   - Aggregation von Energiedaten auf Maschinenebene zur Identifizierung von Ineffizienzen
   - Implementierung von Echtzeitregeln zur Optimierung von Energiesparplänen

3. Predictive Maintenance:
   - Analyse von Vibrations- und Temperaturdaten zur Erkennung potenzieller Geräteausfälle
   - Generieren von Wartungsempfehlungen basierend auf Echtzeitdatenmustern

4. Produktionsplanung und -steuerung:
   - Echtzeitverfolgung des Produktionsfortschritts und Abgleich mit Planzielen  
   - Dynamische Anpassung von Produktionsplänen basierend auf Echtzeitengpässen oder Verzögerungen

## Fazit

Azure Stream Analytics befähigt uns, den vollen Wert unserer IIoT-Daten auszuschöpfen, indem es Echtzeiteinblicke und umsetzbare Erkenntnisse liefert. Durch die nahtlose Integration mit Event Hubs und Power BI schafft Stream Analytics eine leistungsstarke End-to-End-Pipeline für die Datenverarbeitung und -visualisierung.